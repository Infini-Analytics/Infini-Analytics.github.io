# 电信行业的可视化信息分析平台 - ZILLIZ Analytics

## 摘要

数十亿的社交和互联网交互，移动终端日志以及传感器数据在整个电信网络中不断流动。伴随革命性的 5G 通信技术，数据风暴正变得越来越猛烈：

- 数据量爆发式增长，2018 ~ 2025 数据量至少增长 6 倍
- 到 2021 年，全球移动数据流量将达到每月 49 EB
- 数据连接数量指数级，跨越式增长。4G 网络连接密度约 1,000 Connection / KM<sup>2</sup> ，5G 网络连接密度约 1,000,000 Connection / KM<sup>2</sup>

不幸的是，基于 CPU 的传统硬件和分析解决方案太慢，很难扩展。尽管进行了大量投资，但在分析之前，仍然要删除太多有价值的远程信息处理数据，对其进行了预汇总或降采样，从而丢失了大多数细节，导致缺失细节的见解和错误的结论。

为帮助企业用户应对数据时代全新的挑战，ZILLIZ 公司设计研发了新一代海量时空数据可视化分析引擎 ZILLIZ Analytics ，通过 GPU 加速的核心算法，实现电信网络实时运营，助力电信分析人员实时查询和可视化数据。网络分析师和数据科学家可以实时与电信数据进行可视化交互，从而迅速发现有关网络性能，信号强度，安全性，下载速度，信噪比和客户体验质量的可行性报告。

电信公司需要实时数据分析，希望能够快速发现网络异常并在用户受到影响之前解决它们，从而提高服务可用性和网络可靠性。同时还希望及时对网络漏洞警报做出响应，在数据遭到破坏之前修补漏洞。ZILLIZ Analytics 帮助分析师通过查询和研究详细记录，进一步获得地理空间分析功能，以推动基于位置的客户和网络洞察。

另一方面，电信运营商希望围绕人口统计，使用情况，客户帐户，连接性，网络性能和可靠性进行大数据分析，客户支持和服务问题等，以降低客户流失率。 ZILLIZ Analytics 使电信行业的客户流失分析变得简单，分析师可以可视化客户流失，快速又轻松的构建一系列图表，以识别不同数据集或地理位置之间的模式和相关性。

ZILLIZ Analytics 具有完整的自主知识产权，并且率先使用图形处理单元（ GPU ）的大规模并行处理和视觉渲染能力进行数据可视化呈现。与传统方案相比，ZILLIZ Analytics 平台具备高吞吐、高性价比、低延时三重优势，显著降低单位算力成本，对十亿级数据集的查询分析提供亚秒级响应。

![ZILLIZAnalytics](./assets/InfiniAnalytics.jpg)
 **ZILLIZ Analytics 方案包括：**

1. MegaWise 核心数据分析引擎
2. Picasso 图形渲染引擎
3. Infini 可视化交互分析界面


## MegaWise 核心数据分析引擎

### 对 SQL 的原生支持

MegaWise 支持标准 SQL 和 PostgreSQL 语法，提供的查询速度比基于 CPU 的分析平台快一到两个数量级。分析师和数据科学家可以依靠他们现有的 SQL 知识，通过以下方法对数据进行分析：

- 系统的可视化交互界面 （GUI）
- 命令行界面（ CLI ）
- API 库，目前支持 Python，Java，C++
- Java 数据库连接（ JDBC ）和开放式数据库连接（ ODBC ）

### 动态查询编译

MegaWise 是面向 CPU/GPU 异构计算体系结构设计的下一代数据分析平台。对上层应用支持常见的 SQL 分析操作，如过滤、聚合、连接，并提供领域加速算子，如地理信息分析、向量分析、时序分析等。

为了有效屏蔽算法实现的复杂性、计算设备的异构性，并充分挖掘硬件加速器的运算能力，ZILLIZ 在 MegaWise 平台中构建了基于 LLVM 的 JIT 编译系统。LLVM 允许 MegaWise 将查询语句转换为独立于体系结构的中间代码，该中间代码可根据具体的执行硬件环境进一步生成目标代码，并面向硬件进行特定优化。这保证 MegaWise 具有良好的跨平台跨设备能力，当前 MegaWise 可在 NVIDIA GPU ，x64 CPU ，POWER CPU 和 ARM CPU 上高效运行。

MegaWise 的 JIT 系统同时提供了更快的编译速度，单条查询语句的编译时间在 **20 毫秒以下**。结合 MegaWise 的查询计划缓存系统，查询语句的平均编译时间通常在 **10 毫秒以内**。在 JIT 系统的有力支撑下，用户可以基于 SQL 进行便捷的自定义数据分析，并充分利用 CPU/GPU 所构成的混合异构运算能力，而不必关心底层硬件与算法实现的差异性。

### 多级数据缓存

MegaWise 对内存和计算层进行了深度优化，以提供极致性能。MegaWise 在每个物理单节点内构建了 GPU 显存、主存、 SSD 三级缓存。根据数据热度及运算局部性，完成对数据的智能放置。需要被 GPU 频繁、连续处理的热数据，将被保存在 GPU 显存中，避免通过 PCIe 总线移动数据，以实现最快的访问速度。MegaWise 还可以利用 NVIDIA NVLink 技术加速 CPU 到 GPU 的数据传输，速度比没有 NVLink 的系统快 2.5 倍，该特性在可在 IBM OpenPOWER 服务器上使用。

MegaWise 的缓存系统同时提供与外部系统进行数据交互的能力。数据格式全面兼容 Apache Arrow 标准，在 GPU 显存、主存两个内存层均可实现对外数据交换，并支持零拷贝数据传输模式。

### 矢量化查询与混合执行

支撑 MegaWise 超高性能的另一个重要特性是查询执行的高度矢量化。矢量化代码允许处理器同时计算众多数据项。当前的 GPU 单卡内通常包含数以千计乃至数以万计的运算执行单元，这意味着 GPU 中的矢量化查询可在单周期并行处理数千个数据项，相较 CPU 方案，数据处理的并发度提升两到三个数量级。

MegaWise 的矢量化查询技术可以同时应用到 CPU 。现代 CPU 普遍提供了向量扩展指令集，内部集成了可并行处理多个数据项的宽字执行单元。MegaWise 的 SQL Engine 可同时驱动多个 GPU 和 CPU 进行矢量化查询，即便在 CPU 中，在应用矢量化查询后，相较传统多线程方案也有显著的性能提升。

### 终结复杂索引、降采样、预聚合

传统的分析平台在设计之初，并未考虑到当今大数据的数据量、分析算法的复杂度，或决策的速度。随着这些主流分析工具在大型数据集的重压下开始崩溃，传统的数据仓库采用了索引、降采样或预聚合等技术，以支撑大规模数据分析的性能。

相比之下，MegaWise 平台充分发挥 GPU 等硬件加速器的硬件红利，可实现巨大性能提升。通过软硬件一体化融合，MegaWise 可以提供即时查询，而无需事先构建索引、降采样或预聚合，即使面向十亿级数据记录也可以达到几十到几百毫秒的响应速度。

避免构建复杂索引、降采样和预聚合主要带来两点优势。首先，部署 MegaWise 的用户不需要花费大量时间和资源来建模数据，只需完成数据导入即可享受到实时 SQL 查询。其次，只保留对数据的轻量预处理意味着 MegaWise 可以更快速的加载数据，这对于流数据处理场景及高频数据处理场景尤为重要。

### 性能/性价比分析

以下测试中用到的数据与查询语句来自纽约出租车历史订单（共 11 亿笔订单）。

#### 单节点 MegaWise 对比其他集群产品

- 测试环境

|              | 物理节点数 | CPU 总数 | GPU 总数 | 内存总容量（GB） | SSD 磁盘容量（TB） |
| :----------: | ---------: | -------: | -------: | ---------------- | -----------------: |
|   MegaWise   |          1 |       48 |        1 | 256              |                0.5 |
|   Redshift   |          6 |      192 |        0 | 1464             |               15.4 |
|  Spark 2.4   |         21 |       84 |        0 | 315              |                1.7 |
| Presto 0.214 |         21 |       84 |        0 | 315              |                1.7 |

> 友商数据引用自：https://tech.marksblogg.com/benchmarks.html

- 性能数据

|              |   Q1 |   Q2 |   Q3 |    Q4 |
| :----------: | ---: | ---: | ---: | ----: |
|   MegaWise   | 1.82 | 1.69 | 1.81 |  2.81 |
|   Redshift   | 1.56 | 1.25 | 2.25 |  2.97 |
|  Spark 2.4   | 2.36 | 3.56 | 4.02 |  20.4 |
| Presto 0.214 | 3.54 | 6.29 | 7.66 | 11.92 |

> 友商数据引用自：https://tech.marksblogg.com/benchmarks.html

#### 单节点 MegaWise 对比其他单节点产品

- 测试环境

|               | 物理节点数 | CPU 总数 | GPU 总数 | 内存总容量（GB） | SSD 磁盘容量（TB） |
| :-----------: | ---------: | -------: | -------: | ---------------- | -----------------: |
|   MegaWise    |          1 |       48 |        1 | 256              |                0.5 |
|  Oracle 12.2  |          1 |       48 |        0 | 256              |                2.0 |
| PostgreSQL 10 |          1 |      128 |        0 | 1024             |                3.0 |

> 友商数据引用自：https://tech.marksblogg.com/benchmarks.html

- 性能数据

|               |     Q1 |     Q2 |     Q3 |     Q4 |
| :-----------: | -----: | -----: | -----: | -----: |
|   MegaWise    |   1.82 |   1.69 |   1.81 |   2.81 |
|  Oracle 12.2  | 213.82 | 174.59 | 174.81 | 173.84 |
| PostgreSQL 10 |  56.55 |  56.92 |  89.90 |  94.37 |

> 友商数据引用自：https://tech.marksblogg.com/benchmarks.html



## Picasso 图形渲染引擎

### 服务器端渲染

在传统的可视化数据交互系统中，web 端可视化系统通过 JDBC 等接口连接数据库查询引擎，将查询结果传输到前端进行数据栅格化，并通过交互界面展示。这类解决方案面向小数据集工作良好，但在应对海量数据时难以满足数据分析与数据交互的实时性需求。

传统解决方案在多个环节存在问题：

- 数据库需要将结果通过网络传输到前端，在现有网络技术条件下，传输亿级结果需要几秒甚至几分钟的时间。
- 当下流行的前端渲染系统支持的数据规模在十万级，在功能上无法满足海量数据可视化交互的需求。

ZILLIZ Analytics 采用更为先进的服务器端渲染技术，SQL 引擎与渲染引擎均采用 GPU 加速，并已实现无缝整合。SQL 引擎在完成查询分析任务后，调度系统随即将 GPU 计算资源及 GPU 内数据直接调度至渲染引擎。ZILLIZ Analytics 的解决方案直接避免了数据的传输，查询分析与图像渲染两个阶段间实现了数据零拷贝。此外，大量的查询结果数据在 GPU 内已经由渲染引擎栅格化为图片，服务器端只需向 web 前端传输图片，与直接传输结果数据的方案相比，数据传输量降至 1% 以下。

在数据栅格化的过程中，Picasso 图形渲染引擎可充分利用 GPU 内所有的渲染管线，与 web 前端的渲染技术相比，渲染并发度提升三个数量级，亿级数据的渲染速度仍可保证在 100 毫秒以内。

### Vega 描述语言

Vega 描述语言由著名游戏引擎 D3 的创建者开发，旨在对复杂的渲染计划进行准确描述。Picasso 图形渲染引擎完整兼容 Vega 语法。Infini 可视化交互分析界面以及用户的第三方可视化系统均可通过 Vega 接口与 Picasso 图形渲染引擎交互。

通过 Vega 语言，上层应用可向 Picasso 图形渲染引擎发出散点图、热力图、线段、多边形等多类渲染任务。同时，Picasso 图形渲染引擎还内置丰富的数据可视化渲染方式，方便用户快速完成定制化开发。

### 性能分析

| points(K) | t_trans(ms) | t_echarts_render(ms) | echarts(ms) | gis(ms) |
| :-------: | ----------: | -------------------: | ----------: | ------: |
|     1     |          59 |                 1200 |        1259 |     669 |
|     2     |          52 |                 1500 |        1552 |     651 |
|     4     |          93 |                 2000 |        2093 |     636 |
|     8     |         177 |                 1220 |        1397 |     632 |
|    16     |         340 |                 2400 |        2740 |     611 |
|    32     |         668 |                 4000 |        4668 |     600 |
|    64     |        1362 |                 7200 |        8562 |     837 |
|    128    |        2770 |                16300 |       19070 |     704 |
|    256    |        5438 |                40000 |       45438 |     757 |
|    512    |        8902 |                  NAN |         NAN |     985 |

> - t_trans 、 t_echarts_render 、 echarts 三列为前端渲染方案的执行时间
> - t_trans 为数据从后台数据库发送到前端的时间
> - t_echarts_render 为 echarts 渲染时间
> - echarts 为 echarts 方案数据传输与渲染时间之和
> - gis 为 ZILLIZ Analytics 方案渲染与数据传输时间之和

## Infini 可视化交互分析界面

前端组件基于 React 构建，各类图表基于 D3 开发。用户可以灵活配置各个图表，支持针对多列数据进行聚合或者过滤。通过我们特有的 crossfilter sql 生成功能，用户可以进行多 chart 交互操作，并实时更新图表。

目前支持 9 种图表类型，每种图表超过 10 种自定义配置（包括颜色、显示格式等）。

## 时空分析案例

### 纽约出租车

以下案例使用的数据来自开源数据集。

- 汇总分析纽约出租车数年的订单情况（超过3亿笔）

  ![taxi01](./assets/taxi01.jpg)

  > - 地图定位按订单到达位置显示
  > - 数据点按订单金额着色，越红代表订单金额越高

- 缩放地图，分析指定区域的订单情况

  ![taxi04](./assets/taxi02.jpg)

- 按时间窗口与车辆运营商进行分析过滤
  ![taxi03](./assets/taxi03.jpg)

以上分析模式，非常适合类似行业的时空数据分析场景，如快递、物流行业的每月快递信息分析，能够对数亿快递信息进行图像化交互式分析，从而有效实现资源优化配置、优化定价模型等业务分析需求。

### 上海市无线 WIFI 基站信息

以下案例使用的数据来自上海市政府公开数据。

- 上海市某行政区域近两小时 WIFI 基站信息（超过27万个 WIFI 信息采集位点）
  ![渣土车1](./assets/wifi1.png)
- 分析指定区域内的 WIFI 基站信息
  ![渣土车2](./assets/wifi3.png)
- 分析某一网络类型的 WIFI 基站信息
  ![渣土车3](./assets/wifi2.png)

## 总结

新的数据时代，带来新的挑战，传统分析方法与框架面临性能与成本的双重困境。ZILLIZ Analytics 能极大的提升用户对海量结构化数据和时空数据的分析能力。在成本可控的前提下，充分挖掘爆发式增长的数据中蕴含的新价值，借助GPU加速分析功能实现电力电信网络实时运营：

- 快速发现网络异常以进行现场服务和预防性维护
- 了解客户流失的历史模式以建立预测性机器学习模型
- 通过信号强度的地理空间分析改善客户体验

ZILLIZ Analytics 提供了能够解决物流行业各种大数据数据分析需求的统一平台：

- 通过 GPU 加速数据查询和数据可视化的的能力
- 提供了对超大规模时空信息分析的能力远超传统 GIS 解决方案
- 让大数据变得可视化、更及时、更直观
- 让所有用户能够接近零学习成本轻松上手

以上各种优势综合起来加速信息处理，从而更好为物流行业的领导者们提供更好的决策支持。

更多信息欢迎访问我们的网站：https://infini-analytics.github.io/
